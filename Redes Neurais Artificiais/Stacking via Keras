from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense, Flatten, Dropout
from keras.layers.convolutional import Conv1D, MaxPooling1D
from keras.wrappers.scikit_learn import KerasClassifier
from keras.utils import np_utils
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_predict
from sklearn.model_selection import KFold
import numpy as np

# Carregando a base de dados Iris
iris = load_iris()
X = iris.data
y = iris.target

# Dividindo a base de dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Reformatando os dados para a entrada do modelo convolucional
X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

# Convertendo os rótulos em vetores one-hot
y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)
num_classes = y_test.shape[1]

# Definindo a função que cria o modelo convolucional
def create_model():
    model = Sequential()
    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))
    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))
    model.add(MaxPooling1D(pool_size=2))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Convertendo o modelo Keras em um modelo compatível com scikit-learn
model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=10, verbose=0)

# Definindo os modelos base
models = [model, model, model, model]

# Gerando as previsões dos modelos base para a base de treino
X_train_meta = np.zeros((len(X_train), len(models)))
for i, model in enumerate(models):
    y_pred = cross_val_predict(model, X_train, y_train, cv=KFold(n_splits=5, random_state=42))
    X_train_meta[:, i] = y_pred

# Treinando o modelo de metapredição
meta_model = Sequential()
meta_model.add(Dense(128, input_dim=X_train_meta.shape[1], activation='relu'))
meta_model.add(Dense(num_classes, activation='softmax'))
meta_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
meta_model.fit(X_train_meta, y_train, epochs=50, batch_size=10, verbose=0)

# Gerando as previsões dos modelos base para a base de teste
X_test_meta = np.zeros((len(X_test), len(models)))
for i, model in enumerate(models):
    model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=0)
    y_pred = model.predict_classes(X_test)
    X_test_meta[:, i] = y_pred

# Gerando a previsão
# Reformatando a amostra de teste
sample = X_test[0].reshape((1, X_test.shape[1], 1))

# Gerando as previsões dos modelos base para a amostra de teste
X_sample_meta = np.zeros((1, len(models)))
for i, model in enumerate(models):
    y_pred = model.predict_classes(sample)
    X_sample_meta[:, i] = y_pred

# Realizando a previsão com o modelo de metapredição
y_pred = meta_model.predict_classes(X_sample_meta)

# Convertendo a previsão para o rótulo original
prediction = np.argmax(y_pred)

# Imprimindo a previsão
print(f"A amostra de teste é do tipo {iris.target_names[prediction]}")
